"""
Streamlit ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì • ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ì†ŒìŠ¤ë³„ ë°ì´í„° í‘œì‹œ
"""
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import sys
import logging
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
# app/web/web_demo.py -> app/web -> app -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.database.db_manager import init_database, get_db_session
from src.database.models import SentimentAnalysis, CollectedText
from src.trend.trend_utils import TrendAnalyzer
from src.trend.simple_change_detector import SimpleChangeDetector
from src.collectors.collector_manager import CollectorManager

# ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ import
from app.utils import db_queries, visualization, sentiment_analysis, data_download, constants
from app.utils.visualization import (
    calculate_sentiment_score,
    format_number,
    generate_wordcloud,
    create_donut_chart,
    create_gauge_chart,
    create_bar_chart,
    create_trend_chart,
    create_emotion_distribution_chart,
    create_topic_sentiment_chart
)
from app.utils.sentiment_analysis import calculate_sentiment_statistics
from app.utils.sentiment_utils import calculate_sentiment_statistics_from_dict

# ë¡œê¹… ì„¤ì • (ëª¨ë“ˆë³„ ë¡œê·¸ íŒŒì¼ ì‚¬ìš©)
from app.utils.logger_config import app_logger as logger

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Social Sentiment & Trend Monitor",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
init_database("sqlite:///data/database/sentiment.db")


# ì„œë¹„ìŠ¤ ëª¨ë“ˆ import
from app.services import session_manager, monitoring_service, trend_service, youtube_service, emotion_service
from app.components.trend_selector import render_algorithm_selector

# ìºì‹œëŠ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì´ ì•„ë‹ ë•Œë§Œ ì‚¬ìš© (ê¸°ë³¸ê°’: False)
def get_sentiment_data(keyword: str, source: str, hours: int = 24):
    """ê°ì • ë¶„ì„ ë°ì´í„° ì¡°íšŒ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì—ì„œëŠ” ìºì‹œ ì‚¬ìš© ì•ˆ í•¨)"""
    return db_queries.get_sentiment_data(keyword, source, hours)


def get_video_data(keyword: str):
    """YouTube ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì—ì„œëŠ” ìºì‹œ ì‚¬ìš© ì•ˆ í•¨)"""
    return db_queries.get_video_data(keyword)


def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜"""
    st.title("ğŸ“Š Social Sentiment & Trend Monitor")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í†µí•© ê´€ë¦¬)
    session_manager.init_session_state()
    
    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìƒíƒœ í‘œì‹œ
    if st.session_state.realtime_monitoring:
        status_container = st.container()
        with status_container:
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                st.markdown("ğŸŸ¢ **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™œì„±í™”**")
            with col2:
                if st.session_state.last_update_time:
                    elapsed = (datetime.now() - st.session_state.last_update_time).total_seconds()
                    elapsed_minutes = int(elapsed // 60)
                    elapsed_seconds = int(elapsed % 60)
                    if elapsed_minutes > 0:
                        st.markdown(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {elapsed_minutes}ë¶„ {elapsed_seconds}ì´ˆ ì „")
                    else:
                        st.markdown(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {elapsed_seconds}ì´ˆ ì „")
            with col3:
                if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", key="refresh_main"):
                    st.cache_data.clear()
                    st.rerun()
    
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.title("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰
    search_keyword = st.sidebar.text_input(
        "í‚¤ì›Œë“œ ì…ë ¥",
        placeholder="ì˜ˆ: ì˜í™”ë¦¬ë·°, ì•„ì´í°, ë§¥ë¶...",
        key="search_keyword"
    )
    
    # ì†ŒìŠ¤ ì„ íƒ
    st.sidebar.markdown("### ğŸ“± ì •ë³´ ì†ŒìŠ¤ ì„ íƒ")
    source_youtube = st.sidebar.checkbox("YouTube", value=True)
    source_twitter = st.sidebar.checkbox("X (íŠ¸ìœ„í„°)", value=False)
    source_news = st.sidebar.checkbox("ë‰´ìŠ¤", value=False)
    source_blog = st.sidebar.checkbox("ë¸”ë¡œê·¸", value=False)
    
    selected_sources = []
    if source_youtube:
        selected_sources.append("youtube")
    if source_twitter:
        selected_sources.append("twitter")
    if source_news:
        selected_sources.append("news")
    if source_blog:
        selected_sources.append("blog")
    
    # ì¶”í›„ ì¶”ê°€ë  ì„œë¹„ìŠ¤ ì•ˆë‚´
    if source_twitter or source_news or source_blog:
        st.sidebar.info("âš ï¸ X(íŠ¸ìœ„í„°), ë‰´ìŠ¤, ë¸”ë¡œê·¸ëŠ” ì¶”í›„ ì¶”ê°€ë  ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.")
    
    max_results = st.sidebar.number_input(
        "ìˆ˜ì§‘í•  ë°ì´í„° ìˆ˜",
        min_value=5,
        max_value=50,
        value=10,
        step=5
    )
    
    st.sidebar.markdown("---")
    
    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (ê²€ìƒ‰ ë²„íŠ¼ ì „ì— ì •ì˜)
    st.sidebar.markdown("### âš¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    
    realtime_enabled = st.sidebar.checkbox(
        "ì‹¤ì‹œê°„ ìë™ ìˆ˜ì§‘ í™œì„±í™”",
        value=st.session_state.realtime_monitoring,
        help="í™œì„±í™” ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤."
    )
    
    if realtime_enabled != st.session_state.realtime_monitoring:
        st.session_state.realtime_monitoring = realtime_enabled
        if realtime_enabled:
            st.session_state.monitoring_keyword = search_keyword.strip() if search_keyword else None
            st.session_state.monitoring_sources = selected_sources.copy()
            st.session_state.last_update_time = datetime.now()
            st.sidebar.success("âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        else:
            st.sidebar.info("â¸ï¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    st.sidebar.markdown("---")
    
    # ê²€ìƒ‰ ë²„íŠ¼
    if st.sidebar.button("ğŸ” ê²€ìƒ‰ ë° ë¶„ì„", type="primary"):
        if not search_keyword or not search_keyword.strip():
            st.sidebar.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not selected_sources:
            st.sidebar.error("ìµœì†Œ í•˜ë‚˜ì˜ ì†ŒìŠ¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            keyword = search_keyword.strip()
            st.sidebar.info(f"'{keyword}' í‚¤ì›Œë“œë¡œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # ë°ì´í„° ìˆ˜ì§‘
            with st.spinner(f"'{keyword}' ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
                success, result = monitoring_service.run_data_collection(keyword, selected_sources, max_results)
                if success:
                    st.sidebar.success(f"âœ… {result}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    st.sidebar.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            
            # ê°ì • ë¶„ì„ (YouTubeë§Œ)
            if success and "youtube" in selected_sources:
                with st.spinner(f"'{keyword}' ê°ì • ë¶„ì„ ì¤‘..."):
                    success2, analyzed_count = sentiment_analysis.run_sentiment_analysis(keyword, "youtube", 24)
                    if success2:
                        if analyzed_count > 0:
                            st.sidebar.success(f"âœ… {analyzed_count}ê°œ í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ")
                        else:
                            st.sidebar.info("â„¹ï¸ ë¶„ì„í•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.sidebar.error(f"âŒ ê°ì • ë¶„ì„ ì‹¤íŒ¨")
            
            # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì„ íƒì‚¬í•­)
            if realtime_enabled:
                session_manager.update_monitoring_state(keyword, selected_sources)
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.success(f"âœ… '{keyword}' í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ!")
            # ìºì‹œ ì´ˆê¸°í™”
            st.cache_data.clear()
            st.rerun()
    
    hours = st.sidebar.slider("ë¶„ì„ ê¸°ê°„ (ì‹œê°„)", 1, 168, 24)
    
    # íŠ¸ë Œë“œ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    selected_algorithm = render_algorithm_selector()
    
    st.sidebar.markdown("---")
    
    if realtime_enabled:
        interval = st.sidebar.selectbox(
            "ìˆ˜ì§‘ ì£¼ê¸°",
            options=[1, 3, 5, 10, 15, 30],
            index=2,  # ê¸°ë³¸ê°’: 5ë¶„
            format_func=lambda x: f"{x}ë¶„"
        )
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
        if st.session_state.monitoring_keyword and st.session_state.monitoring_sources:
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ë¡œë¶€í„° ê²½ê³¼ ì‹œê°„ í™•ì¸
            if st.session_state.last_update_time:
                elapsed_minutes = (datetime.now() - st.session_state.last_update_time).total_seconds() / 60
                if elapsed_minutes >= interval:
                    with st.sidebar.spinner(f"'{st.session_state.monitoring_keyword}' ìë™ ìˆ˜ì§‘ ì¤‘..."):
                        success, result = monitoring_service.auto_collect_and_analyze(
                            st.session_state.monitoring_keyword,
                            st.session_state.monitoring_sources,
                            interval
                        )
                        if success:
                            session_manager.update_monitoring_state(
                                st.session_state.monitoring_keyword,
                                st.session_state.monitoring_sources
                            )
                            st.sidebar.success(f"âœ… {result}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                            # ìºì‹œ ì´ˆê¸°í™”
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.sidebar.error(f"âŒ ìˆ˜ì§‘ ì‹¤íŒ¨")
            else:
                session_manager.update_monitoring_state(
                    st.session_state.monitoring_keyword,
                    st.session_state.monitoring_sources
                )
        
        # ìë™ ìƒˆë¡œê³ ì¹¨ ì•ˆë‚´
        st.sidebar.markdown("---")
        st.sidebar.info("ğŸ’¡ **íŒ:** ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ë³´ë ¤ë©´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš” (F5 ë˜ëŠ” Cmd+R)")
        
        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.sidebar.button("ğŸ”„ ì§€ê¸ˆ ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            st.rerun()
    
    # ì„¸ì…˜ ìƒíƒœëŠ” ì´ë¯¸ init_session_state()ì—ì„œ ì´ˆê¸°í™”ë¨
    
    # ë©”ì¸ í™”ë©´
    if not search_keyword or not search_keyword.strip():
        st.warning("ğŸ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
        st.info("""
        **ì‚¬ìš© ë°©ë²•:**
        1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”
        2. ì •ë³´ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš” (í˜„ì¬ YouTubeë§Œ ì§€ì›)
        3. 'ê²€ìƒ‰ ë° ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        4. ë°ì´í„° ìˆ˜ì§‘ ë° ê°ì • ë¶„ì„ì´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤
        """)
        return
    
    keyword = search_keyword.strip()
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
    # ì°¸ê³ : Streamlitì˜ download_buttonì€ ë Œë”ë§ ì‹œ dataë¥¼ ìƒì„±í•˜ë¯€ë¡œ,
    # ëŒ€ëŸ‰ ë°ì´í„°ì˜ ê²½ìš° ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    st.markdown("---")
    col1, col2, col3 = st.columns([2, 2, 2])
    
    with col1:
        # ì›ë³¸ ëŒ“ê¸€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        try:
            csv_data = data_download.generate_comments_csv(keyword)
            if csv_data:
                st.download_button(
                    label="ğŸ“¥ ì›ë³¸ ëŒ“ê¸€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name=f"{keyword}_comments_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="download_comments"
                )
        except Exception as e:
            logger.error(f"ëŒ“ê¸€ ë°ì´í„° CSV ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            st.error("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    with col2:
        # ê°ì • ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        try:
            csv_data = data_download.generate_sentiment_csv(keyword)
            if csv_data:
                st.download_button(
                    label="ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name=f"{keyword}_sentiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="download_sentiment"
                )
        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ CSV ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            st.error("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    with col3:
        # í†µê³„ ìš”ì•½ ë‹¤ìš´ë¡œë“œ
        try:
            csv_data = data_download.generate_summary_csv(keyword)
            if csv_data:
                st.download_button(
                    label="ğŸ“ˆ í†µê³„ ìš”ì•½ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name=f"{keyword}_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="download_summary"
                )
        except Exception as e:
            logger.error(f"í†µê³„ ìš”ì•½ CSV ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            st.error("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì „ì²´ íŠ¸ë Œë“œ ì‹œê°í™” (ë³€í™”ì  Highlight)
    st.header(f"ğŸ“ˆ ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„: '{keyword}'")
    
    with get_db_session() as db:
        # ì „ì²´ ê°ì • ë¶„ì„ ë°ì´í„° ì¡°íšŒ
        all_sentiments = db.query(SentimentAnalysis).filter(
            SentimentAnalysis.keyword == keyword,
            SentimentAnalysis.source == "youtube"
        ).order_by(SentimentAnalysis.analyzed_at).all()
        
        if all_sentiments:
            # íŠ¸ë Œë“œ ë¶„ì„ ìˆ˜í–‰
            sentiment_list = []
            for sent in all_sentiments:
                sentiment_list.append({
                    "analyzed_at": sent.analyzed_at,
                    "positive_score": sent.positive_score,
                    "negative_score": sent.negative_score,
                    "neutral_score": sent.neutral_score
                })
            
            # íŠ¸ë Œë“œ ë¶„ì„ ë° ë³€í™”ì  íƒì§€ (ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ì§€ì›)
            try:
                trend_analysis_result = trend_service.analyze_trend_with_change_points(
                    sentiment_list, 
                    method=selected_algorithm  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
                )
                change_points_data = trend_analysis_result.get("change_points", [])
                alerts = trend_analysis_result.get("alerts", [])
                method_used = trend_analysis_result.get("method", "unknown")
            except Exception as e:
                logger.error(f"íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì•Œë¦¼
                st.error(f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                change_points_data = []
                alerts = []
            
            # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„
            df_trend = pd.DataFrame(sentiment_list)
            df_trend['analyzed_at'] = pd.to_datetime(df_trend['analyzed_at'])
            df_trend['sentiment_score'] = df_trend.apply(
                lambda row: calculate_sentiment_score(
                    row['positive_score'],
                    row['negative_score'],
                    row['neutral_score']
                ),
                axis=1
            )
            
            # ì‹œê°„ë³„ ì§‘ê³„ (1ì‹œê°„ ë‹¨ìœ„)
            df_trend['hour'] = df_trend['analyzed_at'].dt.floor('1h')  # 'H' -> 'h' (deprecated ê²½ê³  í•´ê²°)
            hourly_df = df_trend.groupby('hour').agg({
                'sentiment_score': 'mean',
                'positive_score': 'mean',
                'negative_score': 'mean',
                'neutral_score': 'mean'
            }).reset_index()
            
            # Trend ì„ ê·¸ë˜í”„ + ë³€í™”ì  í‘œì‹œ (visualization ëª¨ë“ˆ ì‚¬ìš©)
            fig_trend = create_trend_chart(hourly_df, change_points_data)
            st.plotly_chart(fig_trend, use_container_width=True, key=f"trend_chart_{keyword}")
            
            # ë³€í™”ì  ìƒì„¸ ì •ë³´
            if alerts:
                st.markdown("---")
                st.markdown(f"### ğŸš¨ ë³€í™”ì  ìƒì„¸ ì •ë³´ ({algorithm_display} ì•Œê³ ë¦¬ì¦˜)")
                alerts_df = pd.DataFrame(alerts)
                
                # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ (SimpleChangeDetectorëŠ” previous_score/current_score ì‚¬ìš©)
                available_columns = []
                column_mapping = {
                    'change_point': 'ë³€í™”ì  ì‹œê°„',
                    'change_type': 'ë³€í™” ìœ í˜•',
                    'change_rate': 'ë³€í™”ìœ¨',
                    'previous_score': 'ì´ì „ ê°ì • ì ìˆ˜',
                    'current_score': 'í˜„ì¬ ê°ì • ì ìˆ˜',
                    'previous_sentiment': 'ì´ì „ ê°ì •',
                    'current_sentiment': 'í˜„ì¬ ê°ì •',
                    'window_start': 'êµ¬ê°„ ì‹œì‘',
                    'window_end': 'êµ¬ê°„ ì¢…ë£Œ'
                }
                
                # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
                for col in ['change_point', 'change_type', 'change_rate', 
                           'previous_score', 'current_score', 
                           'previous_sentiment', 'current_sentiment',
                           'window_start', 'window_end']:
                    if col in alerts_df.columns:
                        available_columns.append(col)
                
                if available_columns:
                    display_df = alerts_df[available_columns].copy()
                    # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½
                    display_df.columns = [column_mapping.get(col, col) for col in display_df.columns]
                    st.dataframe(
                        display_df,
                        use_container_width=True,
                        hide_index=True
                    )
                else:
                    st.dataframe(alerts_df, use_container_width=True, hide_index=True)
            elif change_points_data:
                st.info(f"âœ… {len(change_points_data)}ê°œì˜ ë³€í™”ì ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # YouTube ë°ì´í„° í‘œì‹œ
    if "youtube" in selected_sources:
        st.header(f"ğŸ“º YouTube: '{keyword}'")
        
        # í•œ ë²ˆì˜ DB ì„¸ì…˜ìœ¼ë¡œ ëª¨ë“  ë°ì´í„° ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
        try:
            videos, comments_by_video, all_sentiments_dict = youtube_service.get_all_video_data(keyword)
        except Exception as e:
            logger.error(f"YouTube ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
            st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return
        
        if not videos:
            st.warning(f"í‚¤ì›Œë“œ '{keyword}'ì— ëŒ€í•œ YouTube ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ìœ„ì—ì„œ 'ê²€ìƒ‰ ë° ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            return
        
        st.markdown(f"**ì´ {len(videos)}ê°œì˜ ì˜ìƒ**")
        st.markdown("---")
        
        # ê° ë¹„ë””ì˜¤ë³„ë¡œ í‘œì‹œ
        for idx, video in enumerate(videos, 1):
            video_id = video["video_id"]
            
            # ë¹„ë””ì˜¤ ì •ë³´ ì¹´ë“œ
            with st.container():
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.subheader(f"{idx}. {video['title']}")
                    st.markdown(f"**ì±„ë„:** {video['channel_name']}")
                    st.markdown(f"**URL:** [{video['url']}]({video['url']})")
                
                with col2:
                    st.metric("ì¡°íšŒìˆ˜", format_number(video['view_count']))
                    st.metric("ì¢‹ì•„ìš”", format_number(video['like_count']))
                
                # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ëŒ“ê¸€ ë° ê°ì • ë¶„ì„ ê²°ê³¼ (ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©)
                comments = comments_by_video.get(video_id, [])
                # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ëŒ“ê¸€ IDë§Œ í•„í„°ë§
                video_comment_ids = {c.id for c in comments}
                sentiments_dict = {
                    text_id: sent 
                    for text_id, sent in all_sentiments_dict.items() 
                    if text_id in video_comment_ids
                }
                
                if sentiments_dict:
                    # ê°ì • í†µê³„ ê³„ì‚° (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš© - ì¤‘ë³µ ì œê±°)
                    stats = calculate_sentiment_statistics_from_dict(sentiments_dict)
                    sentiment_counts = stats['sentiment_counts']
                    avg_positive = stats['avg_positive']
                    avg_negative = stats['avg_negative']
                    avg_neutral = stats['avg_neutral']
                    overall_sentiment = stats['overall_sentiment']
                    
                    # ìƒìœ„ ëŒ“ê¸€ 5ê°œ í‘œì‹œ
                    st.markdown("---")
                    st.markdown("### ğŸ’¬ ìƒìœ„ ëŒ“ê¸€")
                    
                    # ëŒ“ê¸€ê³¼ ê°ì • ë¶„ì„ ê²°ê³¼ ë§¤ì¹­í•˜ì—¬ ì •ë ¬
                    comment_sentiment_pairs = []
                    for comment in comments[:20]:  # ìµœëŒ€ 20ê°œ ì¤‘ì—ì„œ ì„ íƒ
                        if comment.id in sentiments_dict:
                            sent = sentiments_dict[comment.id]
                            sentiment_score = sent.positive_score - sent.negative_score
                            comment_sentiment_pairs.append((comment, sent, sentiment_score))
                    
                    # ê°ì • ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸ì •/ë¶€ì • ëª¨ë‘ í¬í•¨)
                    comment_sentiment_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
                    top_comments = comment_sentiment_pairs[:5]
                    
                    for i, (comment, sent, score) in enumerate(top_comments, 1):
                        sentiment_label = sent.predicted_sentiment
                        sentiment_emoji = "ğŸ˜Š" if sentiment_label == "positive" else "ğŸ˜¢" if sentiment_label == "negative" else "ğŸ˜"
                        
                        with st.expander(f"{sentiment_emoji} ëŒ“ê¸€ {i}: {comment.text[:50]}..." if len(comment.text) > 50 else f"{sentiment_emoji} ëŒ“ê¸€ {i}: {comment.text}"):
                            st.markdown(f"**ëŒ“ê¸€:** {comment.text}")
                            if comment.author:
                                st.markdown(f"**ì‘ì„±ì:** {comment.author}")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ê¸ì •", f"{sent.positive_score:.2f}", delta=None)
                            with col2:
                                st.metric("ë¶€ì •", f"{sent.negative_score:.2f}", delta=None)
                            with col3:
                                st.metric("ì¤‘ë¦½", f"{sent.neutral_score:.2f}", delta=None)
                    
                    st.markdown("---")
                    
                    # ê°ì • ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    st.markdown("### ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ë¶„ì„ëœ ëŒ“ê¸€", len(sentiments_dict))
                    with col2:
                        st.metric("ê¸ì •", sentiment_counts.get("positive", 0), 
                                delta=f"{sentiment_counts.get('positive', 0)/len(sentiments_dict)*100:.1f}%")
                    with col3:
                        st.metric("ë¶€ì •", sentiment_counts.get("negative", 0),
                                delta=f"{sentiment_counts.get('negative', 0)/len(sentiments_dict)*100:.1f}%")
                    with col4:
                        st.metric("ì¤‘ë¦½", sentiment_counts.get("neutral", 0),
                                delta=f"{sentiment_counts.get('neutral', 0)/len(sentiments_dict)*100:.1f}%")
                    
                    # ì‹œê°ì ì¸ ê·¸ë˜í”„ë“¤ (visualization ëª¨ë“ˆ ì‚¬ìš©)
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig_donut = create_donut_chart(sentiment_counts, "ê°ì • ë¶„í¬")
                        st.plotly_chart(fig_donut, use_container_width=True, key=f"donut_chart_{video_id}_{idx}")
                    
                    with col2:
                        fig_gauge = create_gauge_chart(overall_sentiment, "ì „ì²´ ê°ì • ìŠ¤ì½”ì–´")
                        st.plotly_chart(fig_gauge, use_container_width=True, key=f"gauge_chart_{video_id}_{idx}")
                    
                    fig_bar = create_bar_chart(avg_positive, avg_negative, avg_neutral, "í‰ê·  ê°ì • ì ìˆ˜ ë¶„í¬")
                    st.plotly_chart(fig_bar, use_container_width=True, key=f"bar_chart_{video_id}_{idx}")
                    
                    # 9ê°€ì§€ ê°ì • ë¶„ë¥˜ ì¶”ê°€
                    st.markdown("---")
                    st.markdown("### ğŸ­ 9ê°€ì§€ ê°ì • ë¶„ë¥˜")
                    
                    try:
                        # ëŒ“ê¸€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        comment_texts = [c.text for c in comments if c.id in sentiments_dict]
                        
                        if comment_texts:
                            # ê°ì • ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
                            emotion_svc = emotion_service.EmotionService()
                            
                            # 9ê°€ì§€ ê°ì • ë¶„ë¥˜ ìˆ˜í–‰
                            emotion_results = emotion_svc.analyze_emotions_batch(comment_texts[:100])  # ìµœëŒ€ 100ê°œ
                            emotion_stats = emotion_svc.get_emotion_statistics(emotion_results)
                            
                            # ê°ì • ë¶„í¬ ì°¨íŠ¸ í‘œì‹œ
                            fig_emotion = create_emotion_distribution_chart(emotion_stats)
                            st.plotly_chart(fig_emotion, use_container_width=True, key=f"emotion_chart_{video_id}_{idx}")
                            
                            # ìƒìœ„ ê°ì • í‘œì‹œ
                            if emotion_stats.get("emotion_counts"):
                                top_emotions = sorted(
                                    emotion_stats["emotion_counts"].items(),
                                    key=lambda x: x[1],
                                    reverse=True
                                )[:3]
                                
                                col1, col2, col3 = st.columns(3)
                                for i, (emotion, count) in enumerate(top_emotions):
                                    with [col1, col2, col3][i]:
                                        emotion_label_kr = emotion_svc.get_emotion_label_kr(emotion)
                                        percentage = emotion_stats["emotion_percentages"].get(emotion, 0)
                                        st.metric(
                                            emotion_label_kr,
                                            f"{count}ê°œ",
                                            delta=f"{percentage:.1f}%"
                                        )
                        else:
                            st.info("ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        logger.error(f"9ê°€ì§€ ê°ì • ë¶„ë¥˜ ì‹¤íŒ¨: {e}", exc_info=True)
                        st.warning("ê°ì • ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    
                    # í† í”½-ê°ì • ë¶„ì„ ì¶”ê°€
                    st.markdown("---")
                    st.markdown("### ğŸ“š í† í”½ë³„ ê°ì • ë¶„ì„")
                    
                    try:
                        # ëŒ“ê¸€ í…ìŠ¤íŠ¸ ë° ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                        comment_texts_for_topic = []
                        sentiment_results_for_topic = []
                        
                        for comment in comments[:100]:  # ìµœëŒ€ 100ê°œ
                            if comment.id in sentiments_dict:
                                sent = sentiments_dict[comment.id]
                                comment_texts_for_topic.append(comment.text)
                                sentiment_results_for_topic.append({
                                    "positive_score": sent.positive_score,
                                    "negative_score": sent.negative_score,
                                    "neutral_score": sent.neutral_score
                                })
                        
                        if comment_texts_for_topic:
                            # ê°ì • ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
                            emotion_svc = emotion_service.EmotionService()
                            
                            # í† í”½-ê°ì • ë¶„ì„ ìˆ˜í–‰
                            topic_results = emotion_svc.analyze_topics_with_sentiment(
                                comment_texts_for_topic,
                                sentiment_results_for_topic,
                                use_bertopic=True  # BERTopic ì‚¬ìš© (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´)
                            )
                            
                            # í† í”½ë³„ ê°ì • ì°¨íŠ¸ í‘œì‹œ
                            fig_topic = create_topic_sentiment_chart(topic_results)
                            st.plotly_chart(fig_topic, use_container_width=True, key=f"topic_chart_{video_id}_{idx}")
                            
                            # í† í”½ ìƒì„¸ ì •ë³´ í‘œì‹œ
                            if topic_results.get("topics"):
                                st.markdown("**ì£¼ìš” í† í”½:**")
                                for topic in topic_results["topics"][:5]:  # ìƒìœ„ 5ê°œ
                                    keywords = topic.get("keywords", [])
                                    sentiment = topic.get("sentiment", {})
                                    count = topic.get("count", 0)
                                    
                                    if keywords:
                                        keyword_str = ", ".join(keywords[:3])
                                        st.markdown(f"- **{keyword_str}** ({count}ê°œ ëŒ“ê¸€)")
                                        st.caption(
                                            f"  ê¸ì •: {sentiment.get('avg_positive', 0):.1%}, "
                                            f"ë¶€ì •: {sentiment.get('avg_negative', 0):.1%}, "
                                            f"ì¤‘ë¦½: {sentiment.get('avg_neutral', 0):.1%}"
                                        )
                            
                            # ë¶„ì„ ë°©ë²• í‘œì‹œ
                            method = topic_results.get("method", "unknown")
                            method_label = {
                                "bertopic": "BERTopic (ê³ ê¸‰ í† í”½ ëª¨ë¸ë§)",
                                "keyword_based": "í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„",
                                "none": "ë¶„ì„ ë¶ˆê°€",
                                "error": "ì˜¤ë¥˜ ë°œìƒ"
                            }.get(method, method)
                            st.caption(f"ë¶„ì„ ë°©ë²•: {method_label}")
                        else:
                            st.info("í† í”½ ë¶„ì„ì„ ìœ„í•œ ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        logger.error(f"í† í”½-ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
                        st.warning("í† í”½ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    
                    # Word Cloud ì¶”ê°€
                    st.markdown("---")
                    st.markdown("### â˜ï¸ í‚¤ì›Œë“œ Word Cloud")
                    
                    # ê¸ì •/ë¶€ì • ëŒ“ê¸€ ë¶„ë¦¬
                    positive_texts = []
                    negative_texts = []
                    all_texts = []
                    
                    # ìƒìœ„ ëŒ“ê¸€ì—ì„œ ê¸ì •/ë¶€ì • ë¶„ë¦¬
                    for comment, sent, score in comment_sentiment_pairs:
                        cleaned_text = comment.text
                        sentiment_label = sent.predicted_sentiment.lower()  # ëŒ€ì†Œë¬¸ì í†µì¼
                        
                        if sentiment_label == "positive":
                            positive_texts.append(cleaned_text)
                        elif sentiment_label == "negative":
                            negative_texts.append(cleaned_text)
                        all_texts.append(cleaned_text)
                    
                    # ì „ì²´ ëŒ“ê¸€ì—ì„œë„ ì¶”ê°€ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
                    seen_texts = set(positive_texts + negative_texts)
                    for comment in comments[:100]:  # ë” ë§ì€ ëŒ“ê¸€ í™•ì¸
                        if comment.id in sentiments_dict:
                            sent = sentiments_dict[comment.id]
                            sentiment_label = sent.predicted_sentiment.lower()
                            
                            # ì¤‘ë³µ ì œê±°
                            if comment.text not in seen_texts:
                                if sentiment_label == "positive":
                                    positive_texts.append(comment.text)
                                    seen_texts.add(comment.text)
                                elif sentiment_label == "negative":
                                    negative_texts.append(comment.text)
                                    seen_texts.add(comment.text)
                                all_texts.append(comment.text)
                    
                    # ë””ë²„ê¹… ì •ë³´ (ê°œë°œìš©)
                    # st.write(f"ë””ë²„ê·¸: ê¸ì • {len(positive_texts)}ê°œ, ë¶€ì • {len(negative_texts)}ê°œ")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ê¸ì • í‚¤ì›Œë“œ**")
                        if positive_texts:
                            st.caption(f"ì´ {len(positive_texts)}ê°œì˜ ê¸ì • ëŒ“ê¸€")
                            wordcloud_img = generate_wordcloud(positive_texts, "positive")
                            if wordcloud_img:
                                st.image(wordcloud_img, use_container_width=True)
                            else:
                                st.info("Word Cloud ìƒì„±ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ê¸ì • ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                            # ë””ë²„ê¹…: ê°ì • ë¶„í¬ í™•ì¸
                            sentiment_dist = {}
                            for comment in comments[:20]:
                                if comment.id in sentiments_dict:
                                    sent = sentiments_dict[comment.id]
                                    sentiment_dist[sent.predicted_sentiment] = sentiment_dist.get(sent.predicted_sentiment, 0) + 1
                            if sentiment_dist:
                                st.write(f"ê°ì • ë¶„í¬: {sentiment_dist}")
                    
                    with col2:
                        st.markdown("**ë¶€ì • í‚¤ì›Œë“œ**")
                        if negative_texts:
                            st.caption(f"ì´ {len(negative_texts)}ê°œì˜ ë¶€ì • ëŒ“ê¸€")
                            wordcloud_img = generate_wordcloud(negative_texts, "negative")
                            if wordcloud_img:
                                st.image(wordcloud_img, use_container_width=True)
                            else:
                                st.info("Word Cloud ìƒì„±ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ë¶€ì • ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ë¶„ì„ ì´ìœ  ì„¤ëª…
                    st.markdown("---")
                    st.markdown("### ğŸ’¡ ë¶„ì„ ìš”ì•½")
                    
                    # ê°ì • ë¶„ì„ ê¸°ë°˜ ì„¤ëª… ìƒì„±
                    dominant_sentiment = max(sentiment_counts.items(), key=lambda x: x[1])
                    dominant_ratio = dominant_sentiment[1] / len(sentiments_dict) * 100
                    
                    analysis_text = f"""
                    **ì£¼ìš” ê°ì •:** {dominant_sentiment[0].upper()} ({dominant_ratio:.1f}%)
                    
                    **ë¶„ì„ ê·¼ê±°:**
                    - ì „ì²´ {len(sentiments_dict)}ê°œ ëŒ“ê¸€ ì¤‘ {sentiment_counts.get('positive', 0)}ê°œê°€ ê¸ì •ì , {sentiment_counts.get('negative', 0)}ê°œê°€ ë¶€ì •ì , {sentiment_counts.get('neutral', 0)}ê°œê°€ ì¤‘ë¦½ì ì…ë‹ˆë‹¤.
                    - í‰ê·  ê°ì • ìŠ¤ì½”ì–´ëŠ” {overall_sentiment:.2f}ë¡œ, {'ê¸ì •ì ì¸ ë°˜ì‘ì´ ìš°ì„¸' if overall_sentiment > 0.1 else 'ë¶€ì •ì ì¸ ë°˜ì‘ì´ ìš°ì„¸' if overall_sentiment < -0.1 else 'ì¤‘ë¦½ì ì¸ ë°˜ì‘ì´ ìš°ì„¸'}í•©ë‹ˆë‹¤.
                    - {'ê¸ì •' if avg_positive > avg_negative and avg_positive > avg_neutral else 'ë¶€ì •' if avg_negative > avg_positive and avg_negative > avg_neutral else 'ì¤‘ë¦½'} ê°ì •ì´ ê°€ì¥ ë†’ì€ ë¹„ìœ¨({max(avg_positive, avg_negative, avg_neutral):.1%})ì„ ì°¨ì§€í•©ë‹ˆë‹¤.
                    """
                    
                    st.info(analysis_text)
                else:
                    st.info("ì´ ì˜ìƒì— ëŒ€í•œ ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                st.markdown("---")
    
    # X(íŠ¸ìœ„í„°), ë‰´ìŠ¤, ë¸”ë¡œê·¸ëŠ” ì¶”í›„ ì¶”ê°€ ì•ˆë‚´
    if "twitter" in selected_sources or "news" in selected_sources or "blog" in selected_sources:
        st.markdown("---")
        st.info("""
        **ì¶”í›„ ì¶”ê°€ë  ì„œë¹„ìŠ¤**
        - X (íŠ¸ìœ„í„°): íŠ¸ìœ„í„°/X API ì—°ë™ ì˜ˆì •
        - ë‰´ìŠ¤: ë‰´ìŠ¤ API ì—°ë™ ì˜ˆì •
        - ë¸”ë¡œê·¸: ë¸”ë¡œê·¸ í¬ë¡¤ë§ ê¸°ëŠ¥ ì¶”ê°€ ì˜ˆì •
        
        í˜„ì¬ëŠ” YouTube ë°ì´í„°ë§Œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """)


if __name__ == "__main__":
    main()
